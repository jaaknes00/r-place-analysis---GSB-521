{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d461d-6794-4326-ae41-aa3e89798627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.csv as csv\n",
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "import pyarrow as pa\n",
    "from pyarrow import parquet\n",
    "\n",
    "root_folder_path = '/Users/nicholaseah/Downloads/reddit_csv'  \n",
    "parquet_file = 'combined.parquet'\n",
    "\n",
    "csv_files = glob.glob(os.path.join(root_folder_path, '**/*.csv'), recursive=True)\n",
    "\n",
    "columns_to_read = [\n",
    "    'timestamp' ,'user', 'coordinate', 'pixel_color']\n",
    "\n",
    "# final schema to write to parquet\n",
    "schema = pa.schema([\n",
    "    pa.field('timestamp', pa.string()),\n",
    "    pa.field('user', pa.string()),\n",
    "    pa.field('coordinate', pa.string()),\n",
    "    pa.field('pixel_color', pa.string())\n",
    "])\n",
    "\n",
    "writer = parquet.ParquetWriter(parquet_file, schema, compression='snappy')\n",
    "\n",
    "# support multi-line CSVs\n",
    "parse_options = csv.ParseOptions(newlines_in_values=True)\n",
    "# only read particular columns that we will want. This also helps on \n",
    "# what data canonicalization we need to perform.\n",
    "convert_options=csv.ConvertOptions(include_columns=columns_to_read)\n",
    "\n",
    "for file in csv_files:\n",
    "    print(\"reading\", file)\n",
    "    table = csv.read_csv(file, parse_options=parse_options, convert_options=convert_options)\n",
    "    table = table.cast(schema)\n",
    "    print(\"writing\", file)\n",
    "\n",
    "    # Append table to Parquet file\n",
    "    writer.write_table(table)\n",
    "\n",
    "# Close the Parquet writer\n",
    "if writer:\n",
    "    writer.close()\n",
    "\n",
    "print(f\"Combined CSVs to {parquet_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce72883-a696-4e0d-862d-4727502c0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "parquet_file_path = 'combined.parquet'\n",
    "parquet_file = pq.ParquetFile(parquet_file_path)\n",
    "\n",
    "print(f\"Number of entries (rows) in the Parquet file: {parquet_file.metadata.num_rows:,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a3fca-f9fd-4442-a353-258700b94e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# read the parquet file\n",
    "df = pl.scan_parquet('combined.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ae35a-b7a1-43f1-bf64-9b7a09964abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Coordinate\n",
    "df = pl.scan_parquet('combined.parquet')\n",
    "coordinate_counts = df.group_by(['coordinate']).agg([\n",
    "    pl.col('coordinate').count().alias('coordinate_count')\n",
    "])\n",
    "\n",
    "coordinate_counts.sink_csv('/Users/nicholaseah/Downloads/reddit_csv/coordinate_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff90976-6d51-4cb9-b5b7-08357c622191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Pixel Color\n",
    "df = pl.scan_parquet('combined.parquet')\n",
    "pixel_counts = df.group_by(['pixel_color']).agg([\n",
    "    pl.col('pixel_color').count().alias('pixel_count')\n",
    "])\n",
    "\n",
    "pixel_counts.sink_csv('/Users/nicholaseah/Downloads/reddit_csv/pixel_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d8752-bd32-455f-8b8f-67ec590c846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Timestamps\n",
    "df = pl.scan_parquet('combined.parquet')\n",
    "timestamp_counts = df.group_by(['timestamp']).agg([\n",
    "    pl.col('timestamp').count().alias('timestamp_count')\n",
    "])\n",
    "\n",
    "timestamp_counts.sink_csv('/Users/nicholaseah/Downloads/reddit_csv/timestamp_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4473e83-2b78-4058-9865-1c3a044c13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Users\n",
    "df = pl.scan_parquet('combined.parquet')\n",
    "user_counts = df.group_by(['user']).agg([\n",
    "    pl.col('user').count().alias('user_count')\n",
    "])\n",
    "\n",
    "pixel_counts.sink_csv('/Users/nicholaseah/Downloads/reddit_csv/user_counts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
